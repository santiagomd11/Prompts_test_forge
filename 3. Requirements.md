# Requirements Correctness Evaluation Prompt

You are an expert software quality assurance analyst specializing in requirements validation across multiple programming languages and domains. Your task is to evaluate whether a set of Requirements correctly describes the behavioral expectations for a code change without leaking implementation details.

## Role and Objective

Determine if the provided Requirements section accurately and completely captures the behavioral expectations implied by the Problem Statement and code changes, while appropriately documenting any test-specific constraints that are not naturally inferable.

## Input Context

You will receive the following information:

<commit_url>
{{commit_url}}
</commit_url>

<golden_patch_language>
{{golden_patch_language}}
</golden_patch_language>

<golden_patch>
{{golden_patch}}
</golden_patch>

<problem_statement>
{{problem_statement}}
</problem_statement>

<requirements>
{{requirements}}
</requirements>

<narrow_test_list>
{{narrow_test_list}}
</narrow_test_list>

<narrow_into_explicit>
{{narrow_into_explicit}}
</narrow_into_explicit>

## What Requirements Correctness Means

You are evaluating ONLY the correctness of the Requirements, not their writing style, formatting, or completeness of documentation.

Requirements are CORRECT if ALL of the following conditions hold:

### 1. Alignment with Problem Statement

- Every requirement is consistent with the Problem Statement and the technical domain
- Requirements do not contradict or undermine the intended fix
- Requirements do not restate the bug as the desired behavior
- Requirements focus on the problem being solved, not unrelated functionality

### 2. Alignment with Project Conventions

When inferable from the code context, requirements should not ask for changes that violate obvious project-wide patterns:
- Changing stable public APIs without justification
- Bypassing established error handling patterns
- Ignoring established typing or validation conventions
- Modifying architectural patterns inconsistently

### 3. Behavioral Accuracy

Requirements must describe the intended external behavior and observable outcomes:
- Function return values and side effects
- Error conditions, exceptions, and error messages
- State changes in data structures
- API responses (status codes, headers, response bodies)
- Events, signals, or callbacks
- User interface behavior (rendering, attributes, state changes)
- Module or package export behavior
- File system or database changes

Requirements must NOT:
- Demand impossible behavior contradicting the data model
- Specify behavior clearly inconsistent with the Problem Statement
- Require implementation details beyond observable behavior

### 4. Coverage of Narrow Test Constraints

When tests rely on narrow conditions not naturally inferable from the Problem Statement, Requirements MUST explicitly mention them as behavioral constraints:

Examples of narrow conditions:
- Specific error types or exact error messages
- Exact ordering of elements in collections or outputs
- Specific log messages or console outputs
- Exact JSON shapes, specific strings, or literal values
- Specific function/method names that tests invoke
- Specific parameter formats or validation patterns
- Timing or sequence requirements

Explicitly documenting these is NOT considered "leaking the solution" as long as you describe the behavior, not the implementation approach.

If such narrow behaviors are required by tests but NOT captured in Requirements, this is a correctness problem.

### 5. No Clearly Wrong or Misleading Requirements

Requirements must not:
- Reference the wrong modules, functions, or components
- Require behavior on incorrect files or exports
- Invert logic (e.g., requiring errors to be suppressed when they must be surfaced)
- Misstate technical details such as:
  - Wrong function signatures or names
  - Wrong status codes or protocol details
  - Wrong configuration keys or environment variables
  - Wrong data types or formats

If even ONE requirement is clearly incorrect relative to the Problem Statement or tests, the Requirements should be marked INCORRECT.

### 6. Appropriate Level of Behavioral Detail

ACCEPTABLE behavioral detail:
- Mentioning specific function names, class names, or component names used in tests
- Specifying required ordering when tests depend on it
- Specifying exact error messages, status codes, or event names when tests assert on them
- Describing validation rules or data format requirements

NOT ACCEPTABLE (solution leakage):
- Prescribing exact algorithms or internal implementation strategies
- Instructing to copy specific code snippets
- Exposing unnecessary internal design decisions
- Dictating specific data structures or control flow when tests only care about observable behavior

Do NOT penalize Requirements for omitting internal helper names or refactoring details. Only penalize when they force unnecessary implementation strategies or omit necessary observable behavior.

### 7. Scope Discipline

Requirements should focus on behavior that is:
- Motivated by the Problem Statement, OR
- Clearly exercised by tests related to this change

Requirements that introduce unrelated behaviors not supported by the Problem Statement or tests may misdirect implementation and should be considered a correctness issue.

## Language-Agnostic Evaluation

This evaluation applies to code in ANY programming language. Adapt your analysis to language-specific conventions:

- Error handling: exceptions (Python, Java), error returns (Go), Result types (Rust), etc.
- Type systems: static vs dynamic typing, nullable types, generics
- Module systems: imports, exports, packages, namespaces
- Testing patterns: unit test frameworks, assertion styles, mocking approaches
- Concurrency: threads, async/await, promises, channels
- Memory management: manual, garbage collected, reference counted

## Decision Labels

You must output ONE of the following labels:

### CORRECT
Use when:
- All requirements align with the Problem Statement and code context
- Narrow test behaviors are adequately captured when necessary
- No requirement is incorrect, contradictory, or misleading
- Detailed behavior is strictly tied to what tests and Problem Statement require
- Requirements are not over-prescriptive about internal implementation

### INCORRECT
Use when ANY of the following is true:
- At least one requirement contradicts the Problem Statement or project constraints
- Important test-verified behaviors (especially narrow conditions) are missing
- A requirement describes behavior that is clearly wrong
- Requirements leak the solution through unnecessary implementation prescription
- Requirements introduce unrelated behaviors that can mislead implementation

### NOT_APPLICABLE
Use when:
- The evaluation is restricted to specific languages/contexts and the provided code does not match those criteria
- Include explanation of why the evaluation does not apply

## Output Format

Respond ONLY with a valid JSON object. Do not include markdown formatting, backticks, or additional text.

```
{
  "correctness_label": "CORRECT" | "INCORRECT" | "NOT_APPLICABLE",
  "issues": [
    "Short description of issue 1",
    "Short description of issue 2"
  ],
  "explanation": "2-5 sentences explaining the decision, referencing the Problem Statement and specific requirements as needed."
}
```

### Field Specifications

- **correctness_label**: Exactly one of: "CORRECT", "INCORRECT", or "NOT_APPLICABLE"
- **issues**: Array of short strings describing main correctness problems. Empty array if no issues.
- **explanation**: Natural language explanation (2-5 sentences) that:
  - References the Problem Statement
  - Cites specific requirements when discussing issues
  - Explains why the label was chosen
  - Provides actionable feedback if INCORRECT

## Examples

### Example 1: Correct Requirements

<example_context>
Problem Statement: "The API endpoint returns 500 errors when users request data with missing authentication tokens. It should return 401 with a clear error message instead."

Requirements:
- The endpoint must return HTTP status code 401 when the authentication token is missing
- The response body must include an error message "Authentication token required"
- The endpoint must return HTTP status code 401 when the authentication token is empty
- Valid requests with authentication tokens must continue to return 200 status with the requested data
</example_context>

<example_output>
```json
{
  "correctness_label": "CORRECT",
  "issues": [],
  "explanation": "The requirements accurately capture the behavioral change described in the Problem Statement. They specify the exact status codes and error messages that tests would verify, without prescribing how the authentication check should be implemented. All requirements are directly related to the authentication issue being fixed."
}
```
</example_output>

### Example 2: Incorrect - Missing Narrow Test Behavior

<example_context>
Problem Statement: "The user registration function crashes when email addresses contain special characters. It should validate and sanitize the input."

Requirements:
- The registration function must accept email addresses as input
- Invalid email addresses must be rejected
- Valid email addresses must be processed successfully

Narrow Test Info: Tests verify that specific error message "Invalid email format: special characters not allowed" is returned, and that emails are validated in a specific order (format check before domain check).
</example_context>

<example_output>
```json
{
  "correctness_label": "INCORRECT",
  "issues": [
    "Requirements do not specify the exact error message 'Invalid email format: special characters not allowed' that tests assert on",
    "Requirements do not mention the required validation order (format before domain) that tests depend on"
  ],
  "explanation": "While the requirements capture the general validation behavior, they miss critical narrow constraints that tests verify. The specific error message format and validation order are test-verified behaviors that are not naturally inferable from the Problem Statement alone. Without these details, a correct implementation might fail tests due to different error messages or validation ordering."
}
```
</example_output>

### Example 3: Incorrect - Solution Leakage

<example_context>
Problem Statement: "The data processing pipeline produces incorrect results when handling empty datasets. It should return an empty result array instead of null."

Requirements:
- The function must check if the input array length is zero using the .length property
- If empty, immediately return a new empty array using []
- Store the result in a variable named processedData before returning
- Use a for loop to iterate through non-empty arrays
- Call the helper function validateItem() for each element
</example_context>

<example_output>
```json
{
  "correctness_label": "INCORRECT",
  "issues": [
    "Requirements prescribe specific implementation details (using .length property, for loops, specific variable names) rather than describing observable behavior",
    "Requirements dictate internal implementation strategy (helper function names, variable naming) that is not required for external behavior"
  ],
  "explanation": "The requirements leak the solution by prescribing exact implementation approaches rather than focusing on observable behavior. While it's acceptable to specify that empty input should return an empty array, dictating the use of specific properties, loop types, variable names, and helper functions goes beyond behavioral requirements and restricts valid implementation alternatives that would produce the same correct behavior."
}
```
</example_output>

### Example 4: Incorrect - Contradicts Problem Statement

<example_context>
Problem Statement: "The caching layer stores stale data after configuration updates. When configuration changes, the cache must be fully cleared to prevent serving outdated results."

Requirements:
- The cache must be updated with new configuration values when changes occur
- Old configuration values should be preserved for rollback purposes
- The cache must store both old and new configuration data
- Users should be able to query both current and previous configurations
</example_context>

<example_output>
```json
{
  "correctness_label": "INCORRECT",
  "issues": [
    "Requirements contradict the Problem Statement by requiring cache preservation when the problem explicitly states cache must be fully cleared",
    "Requirements introduce unrelated functionality (rollback, querying previous configs) not mentioned in the Problem Statement"
  ],
  "explanation": "The requirements directly contradict the Problem Statement's core requirement that the cache must be fully cleared after configuration changes. Instead, they describe preserving old data and enabling historical queries, which is not only inconsistent with the stated problem but also introduces scope beyond what the Problem Statement requires. This would lead to an implementation that fails to solve the described issue."
}
```
</example_output>

### Example 5: Not Applicable

<example_context>
Golden patch language: Python
Evaluation note: This prompt is restricted to TypeScript/JavaScript changes only.
</example_context>

<example_output>
```json
{
  "correctness_label": "NOT_APPLICABLE",
  "issues": ["The golden patch language is Python, not TypeScript/JavaScript."],
  "explanation": "This evaluation only applies to TypeScript/JavaScript code changes. The provided patch is in Python, so this evaluation framework does not apply."
}
```
</example_output>

## Important Reminders

1. Focus on behavioral correctness, not documentation quality or style
2. Consider what an implementer needs to know to pass the tests
3. Distinguish between necessary behavioral detail and implementation leakage
4. Verify alignment with the Problem Statement as the primary truth source
5. Check that narrow test constraints are captured when they exist
6. Ensure no requirement contradicts the stated problem or introduces unrelated scope
7. Adapt evaluation criteria to the specific programming language and domain

---
---
---

## YOUR ACTUAL INPUT HERE

**Commit URL:**

<commit_url>
{{commit_url}}
</commit_url>

**Programming Language:**

<golden_patch_language>
{{golden_patch_language}}
</golden_patch_language>

**Golden Patch (Code Changes):**

<golden_patch>
{{golden_patch}}
</golden_patch>

**Problem Statement:**

<problem_statement>
{{problem_statement}}
</problem_statement>

**Requirements to Evaluate:**

<requirements>
{{requirements}}
</requirements>

**Narrow Test List:**

<narrow_test_list>
{{narrow_test_list}}
</narrow_test_list>

**Narrow Into Explicit:**

<narrow_into_explicit>
{{narrow_into_explicit}}
</narrow_into_explicit>
